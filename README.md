# Coursera_Machine_Learning
## Week 1
### Introduction
- Supervised Learning
  - Regression -> Predict continuous output
    - Example: Given data about the size of houses on the real estate market, try to predict the price.
  - Classification -> Discrete value of output
    - Example: Given a patient with a tumor, predict whether the tumor is malignant or benign
- Unsupervised Learning
  - Unsupervised learning allows us to approach problems with little or no idea what our results should look like.
  - We can derive structure from data where we don't know necessarily know the effect of the variables. 
  - Clustering
### Model and Cost Function
  - Cost Function
### Parameter Learning
  - Gradient Descent
### Linear Algebra
  - Matrices and Vectors
  - Addition and Scalar Multiplication
  - Matrix Multiplication
  - Inverse and Transpose

## Week 2
### Environment Setup Instruction
  - Octave or MATLAB
  - ![equation](https://latex.codecogs.com/svg.image?h(x)&space;=\theta&space;_{0}*x_{0}&space;&plus;\theta&space;_{1}*x_{1}&space;&plus;&space;\theta&space;_{2}*x_{2}&space;&plus;&space;...&space;&plus;&space;\theta&space;_{n}*x_{n})
### Multivariate Linear Regressioon
  - Multiple Features
  - Gradient Descent For Multiple Variables
    - Normalization
  - Features and Polynmial Regression
### Coputing Parameters Analytically
  - Normal Equation
    - Don't need Î±
    - Don't need to iterate
    - Need to compute ![equation](https://latex.codecogs.com/svg.image?(X^{T}*X)^{-1})
    - Slow if n is very large (eg. n > 10000)
  - Normal Equation Noninvertibility

## Week 3
### Classification and Representation
  - Classification
    - Logistic Regression
  - Hypothesis Representation
    - sigmoid function
  - Decision Boundary

### Logistic Regression Model
